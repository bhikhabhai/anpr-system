ğŸš— ANPR Backend (FastAPI + Supabase + ONNX)

Automated Number Plate Recognition backend with modular inference endpoints for image, video, and live stream processing.
Designed for scalability using FastAPI, ONNX Runtime, Supabase Storage, and PostgreSQL.

ğŸ“ Project Structure
backend/
â”‚   .env
â”‚   requirements.txt
â”‚   run.md
â”‚
â”œâ”€â”€â”€app
â”‚   â”‚   main.py
â”‚   â”‚   __init__.py
â”‚
â”‚   â”œâ”€â”€â”€api
â”‚   â”‚       infer_image.py
â”‚   â”‚       infer_video.py
â”‚   â”‚       infer_stream.py
â”‚
â”‚   â”œâ”€â”€â”€core
â”‚   â”‚       config.py
â”‚   â”‚       supabase_client.py
â”‚
â”‚   â””â”€â”€â”€services
â”‚           db.py
â”‚           inference.py
â”‚           models.py
â”‚           storage.py
â”‚
â”œâ”€â”€â”€models
â”‚       car_detector.onnx
â”‚
â””â”€â”€â”€outputs

ğŸ§ª Features
Feature	Status
Image inference	âœ”ï¸ Implemented
Video inference	ğŸš§ Placeholder
Stream inference	ğŸš§ Placeholder
Upload annotated image to Supabase	âœ”ï¸ Done
Store metadata in PostgreSQL	âœ”ï¸ Done
Modular API routers	âœ”ï¸ Done
âš™ï¸ Requirements

Python 3.9+

Virtual environment recommended

ğŸ“¦ Installation & Setup
1ï¸âƒ£ Clone repository
git clone <your-repo-url>
cd backend

2ï¸âƒ£ Create and activate virtual environment
Windows
python -m venv venv
venv\Scripts\activate

macOS/Linux
python3 -m venv venv
source venv/bin/activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Environment Configuration

Create a .env file in project root:

SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=service_role_xxxxx
DATABASE_URL=postgresql+psycopg://username:password@host:5432/postgres


Ensure your Supabase Storage bucket exists (e.g., anpr-frames).

â–¶ï¸ Run the Backend
uvicorn app.main:app --reload --port 8000


API will be live at:

Base URL: http://localhost:8000

API Docs: http://localhost:8000/docs

ğŸ”Œ API Endpoints
Endpoint	Method	Description
/health	GET	Check server status
/infer/image	POST	Upload & infer single image
/infer/video	POST	Process full video (WIP)
/infer/stream	POST	Start live camera/RTSP stream pipeline (WIP)

Example call (image inference):

curl -X POST "http://localhost:8000/infer/image" \
-F "file=@sample.jpg"

ğŸ§  Inference Pipeline (Planned Final Workflow)
Raw Image â†’ Vehicle Detection ONNX â†’ Plate Detection ONNX â†’ OCR ONNX
       â†“
Draw bounding boxes + plate text
       â†“
Upload annotated image to Supabase Storage
       â†“
Store metadata + URL in PostgreSQL

ğŸ—ƒï¸ Output Data Model

Stored per inference:

annotated image URL

timestamp

vehicle count

detected plate list

bounding boxes (vehicle + plate)

ğŸš€ Deployment Targets (Future)

Dockerized deployment

Render/Railway/Supabase Edge Functions

Streaming inference with GPU support (Jetson / CUDA optional)

ğŸ“Œ Roadmap
Task	Status
Supabase connection	âœ”ï¸ Completed
Image inference endpoint	âœ”ï¸ Completed
Video support	ğŸš§ Pending
Stream processing	ğŸš§ Pending
Authentication & UI integration	ğŸ•’ Later phase
License

MIT â€” Use it, break it, improve it.